Analyzing compound nouns is one of the crucial issues for natural language processing systems , in particular for those systems that aim at a wide coverage of domains .
In this paper , we propose a method to analyze structures of Japanese compound nouns by using both word collocations statistics and a thesaurus .
An experiment is conducted with 160,000 word collocations to analyze compound nouns of with an average length of 4.9 characters .
The accuracy of this method is about 80 % .
Analyzing compound nouns is one of the crucial issues for natural language processing systems , in particular for those systems that aim at a wide coverage of domains .
Registering all compound nouns in a dictionary is an impractical approach , since we can create a new compound noun by combining nouns .
Therefore , a mechanism to analyze the structure of a compound noun from the individual nouns is necessary .
In order to identify structures of a compound noun , we must first find a set of words that compose the compound noun .
This task is trivial for languages such as English , where words are separated by spaces .
The situation is worse , however , in Japanese where no spaces are placed between words .
The process to identify word boundaries is usually called segmentation .
In processing languages such as Japanese , ambiguities in segmentation should be resolved at the same time as analyzing structure .
For instance , the Japanese compound noun `` SinGataKansetuZei '' ( new indirect tax ) , produces  segementations possibilities for this case ( by consulting a Japanese dictionary , we would filter out some ) .
In this case , we have two remaining possibilities : `` Sin ( new ) / Gata ( type ) / Kansetu ( indirect ) / Zei ( tax ) '' and `` SinGata ( new ) / Kansetu ( indirect ) / Zei ( tax ) '' .
We must choose the correct segmentation , `` SinGata ( new ) / Kansetu ( indirect ) / Zei ( tax ) '' and analyze structure .
Segmentation of Japanese is difficult only when using syntactic knowledge .
Therefore , we could not always expect a sequence of correctly segmented words as an input to structure analysis .
The information of structures is also expected to improve segmentation accuracy .
There are several researches that are attacking this problem .
Fuzisaki et al. applied the HMM model to segmentation and probabilistic CFG to analyzing the structure of compound nouns Fijisaki et al. 1991 .
The accuracy of their method is 73 % in identifying correct structures of kanzi character sequences with average length is 4.2 characters .
In their approach , word boundaries are identified through purely statistical information ( the HMM model ) without regarding such linguistic knowledge , as dictionaries .
Therefore , the HMM model may suggest an improper character sequence as a word .
Furthermore , since nonterminal symbols of CFG are derived from a statistical analysis of word collocations , their number tends to be large and so the number of CFG rules are also large .
They assumed compound nouns consist of only one character words and two character words .
It is questionable whether this method can be extended to handle cases that include more than two character words without lowering accuracy .
In this paper , we propose a method to analyze structures of Japanese compound nouns by using word collocational information and a thesaurus .
The collocational information is acquired from a corpus of four kanzi character words .
For each possible structure of a compound noun , the preference is calculated based on this collocational information and the structure with the highest score wins .
Hindle and Rooth also used collocational information to solve ambiguities of pp-attachment in English Hindle and Rooth 1991 .
Ambiguities are resolved by comparing the strength of associativity between a preposition and a verb and the preposition and a nominal head .
The strength of associativity is calculated on the basis of occurrence frequencies of word collocations in a corpus .
Besides the word collocations information , we also use semantic knowledge , namely , a thesaurus .
The structure of this paper is as follows : Section  explains the knowledge for structure analysis of compound nouns and the procedures to acquire it from a corpus , Section  describes the analysis algorithm , and Section  describes the experiments that are conducted to evaluate the performance of our method , and Section  summarizes the paper and discusses future research directions .
This section describes procedures to acquire collocational information for analyzing compound nouns from a corpus of four kanzi character words .
What we need is occurrence frequencies of all word collocations .
It is not realistic , however , to collect all word collocations .
We use collocations from thesaurus categories that are word abstractions .
We use a corpus of four kanzi character words as the knowledge source of collocational information .
The reasons are as follows :
In Japanese , kanzi character sequences longer than three are usually compound nouns , This tendency is confirmed by comparing the occurrence frequencies of kanzi character words in texts and those headwords in dictionaries .
We investigated the tendency by using sample texts from newspaper articles and encyclopedias , and Bunrui Goi Hyou ( BGH for short ) , which is a standard Japanese thesaurus .
The sample texts include about 220,000 sentences .
We found that three character words and longer represent 4 % in the thesaurus , but 71 % in the sample texts .
Therefore a collection of four kanzi character words would be used as a corpus of compound nouns .
Four kanzi character sequences are useful to extract binary relations of nouns , because dividing a four kanzi character sequence in the middle often gives correct segmentation .
Our preliminary investigation shows that the accuracy of the above heuristics is 96 % ( 961 / 1000 ) .
There is a fairly large corpus of four kanzi character words created by Prof. Tanaka Yasuhito at Aiti Syukutoku college Tanaka 1992 .
The corpus was manually created from newspaper articles and includes about 160,000 words .
After collecting word collocations , we must assign a thesaurus category to each word .
This is a difficult task because some words are assigned multiple categories .
In such cases , we have several category collocations from a single word collocation , some of which are incorrect .
Fortunately , there are few words that are assigned multiple categories in BGH. Therefore , we use method  .
Word collocations containing words with multiple categories represent about 1/3 of the corpus .
If we used other thesauruses , which assign multiple categories to more words , we would need to use method  ,  , or  .
Note : we do not care about frequencies of word collocations prior to replacing words with thesaurus categories .
We assume that a structure of a compound noun can be expressed by a binary tree .
We also assume that the category of the right branch of a ( sub ) tree represents the category of the ( sub ) tree itself .
This assumption exsists because Japanese is a head-final language , a modifier is on the left of its modifiee .
With these assumptions , a preference value of a structure is calculated by recursive function p as follows :
where function l and r return the left and right subtree of the tree respectively , cat returns thesaurus categories of the argument .
If the argument of cat is a tree , cat returns the category of the rightmost leaf of the tree .
Function cv returns an associativity measure of two categories , which is calculated from the frequency of category collocation described in the previous section .
We would use two measures for cv :  returns the relative frequency of collation  , which appears on the left side and  , which appears on the right .
Probability :
Modified mutual information statistics ( MIS ) :
where * means don't care .
MIS is similar to mutual infromation used by Church to calculate semantic dependencies between words Church et al. 1991 .
MIS is different from mutual information because MIS takes account of the position of the word ( left / right ) .
Let us consider an example `` SinGataKansetuZei '' .
Segmentation :
two possibilities ,
remain as mentioned in section  .
Category assignment :
assigning thesaurus categories provides :
A three-digit number stands for a thesaurus category .
A colon `` : '' separates multiple categories assigned to a word .
Preference calculation :
For the case  , the possible tructures are [ [ 118 , 311 ] , 137 ] and [ 118 , [ 311 , 137 ] ] .
We represent a tree with a list notation .
For the case  , there is an ambiguity with the category `` Sin '' [ 118:141:111 ] .
We expand the ambiguity to 15 possible structures .
Preferences are calculated for 17 cases .
For example , the preference of structure [ [ 118 , 311 ] , 137 ] is calculated as follows :
We extract kanzi character sequences from newspaper editorials and columns and encyclopedia text , which has no overlap with the training corpus : 954 compound nouns consisting of four kanzi characters , 710 compound nouns consisting of five kanzi characters , and 786 compound nouns consisting of six kanzi characters are manually extracted from the set of the above kanzi character sequences .
These three collections of compound nouns are used for test data .
We use a thesaurus BGH , which is a standard machine readble Japanese thesaurus .
BGH is structured as a tree with six hierarchical levels .
Table  shows the number of categories at all levels .
In this experiment , we use the categories at level 3 .
If we have more compound nouns as knowledge , we could use a finer hierarchy level .
As mentioned in Section  , we create a set of collocations of thesaurus categories from a corpus of four kanzi character sequences and BGH .
We analyze the test data according to the procedures described in Section  .
In segmentation , we use a heuristic `` minimizing the number of content words '' in order to prune the search space .
This heuristics is commonly used in the Japanese morphological analysis .
The correct structures of the test data manually created in advance .
Table  shows the result of the analysis for four , five , and six kanzi character sequences .
``  '' means that the correct answer was not obtained because the heuristics is segmentation filtered out from the correct segmentation .
The first row shows the percentage of cases where the correct answer is uniquely identified , no tie .
The rows , denoted ``  '' , shows the percentage of correct answers in the n-th rank .
 shows the percentage of correct answers ranked lower or equal to 4th place .
Regardless , more than 90 % of the correct answers are within the second rank .
The probabilistic measure  provides better accuracy than the mutual information measure  for five kanzi character compound nouns , but the result is reversed for six kanzi character compound nouns .
The results for four kanzi character words are almost equal .
In order to judge which measure is better , we need further experiments with longer words .
We could not obtain correct segmentation for 11 out of 954 cases for four kanzi character words , 39 out of 710 cases for five kanzi character words , and 15 out of 787 cases for six kanzi character words .
Therefore , the accuracy of segmentation candidates are 99 % ( 943 / 954 ) , 94.5 % ( 671 / 710 ) and 98.1 % ( 772 / 787 ) respectively .
Segmentation failure is due to words missing from the dictionary and the heuristics we adopted .
As mentioned in Section  , it is difficult to correct segmentation by using only syntactic knowledge .
We used the heuristics to reduce ambiguities in segmentation , but ambiguities may remain .
In these experiments , there are 75 cases where ambiguities can not be solved by the heuristics .
There are 11 such cases for four kanzi character words , 35 such cases for five kanzi character words , and 29 cases for six kanzi character words .
For such cases , the correct segmentation can be uniquely identified by applying the structure analysis for 7 , 19 , and 17 cases , and the correct structure can be uniquely identified for 7 , 10 , and 8 cases for all collections of test data by using  .
On the other hand , 4 , 18 , and 21 cases correctly segmented and 7 , 11 , and 8 cases correctly analyzed their structures for all collections by using  .
For a sequence of segmented words , there are several possible structures .
Table  shows possible structures for four words sequence and their occurrence in all data collections .
Since a compound noun of our test data consists of four , five , and six characters , there could be cases with a compound noun consisting of four , five , or six words .
In the current data collections , however , there are no such cases .
In table  , we find significant deviation over occurrences of structures .
This deviation has strong correlation with the distance between modifiers and modifees .
The rightmost column ( labeled  ) shows sums of distances between modifiers and modifiee contained in the structure .
The distance is measured based on the number of words between a modifier and a modifiee .
For instance , the distance is one , if a modifier and a modifiee are immediately adjacent .
The correlation between the distance and the occurrence of structures tells us that a modifier tends to modify a closer modifiee .
This tendency has been experimentally proven by Maruyama et al. 1992 .
The tendency is expressed by the formula that follows :
where d is the distance between two words and q ( d ) is the probability when two words of said distance is d and have a modification relation .
We redifined cv by taking this tendency as the formula that follows :
where cv ' is redifined cv.
Table  shows the result by using new cvs .
We obtained significant improvement in 5 kanzi and 6 kanzi collection .
We assumed that the thesaurus category of a tree be represented by the category of its right branch subtree because Japanese is a head-final language .
However , when a right subtree is a word such as suffixes , this assumption does not always hold true .
Since our ultimate aim is to analyze semantic structures of compound nouns , then dealing with only the grammatical head is not enough .
We should take semantic heads into consideration .
In order to do so , however , we need knowledge to judge which subtree represents the semantic features of the tree .
This knowledge may be extracted from corpora and machine readable dictionaries .
A certain class of Japanese nouns ( called Sahen meisi ) may behave like verbs .
Actually , we can make verbs from these nouns by adding a special verb `` - suru '' .
These nouns have case frames just like ordinary verbs .
With compound nouns including such nouns , we could use case frames and selectional restrictions to analyze structures .
This process would be almost the same as analyzing ordinary sentences .
We propose a method to analyze Japanese compound nouns using collocational information and a thesaurus .
We also describe a method to acquire the collocational information from a corpus of four kanzi character words .
The method to acquire collocational information is dependent on the Japanese character , but the method to calculate preferences of structures si applicable to any language with compound nouns .
The experiments show that when the method analyzes compound nouns with an average length 4.9 , it produces an accuracy rate of about 83 .
